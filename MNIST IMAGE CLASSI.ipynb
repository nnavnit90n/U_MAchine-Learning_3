{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historically, the computer vision has the  one of the most challengng problem\n",
    "#Advanced in deep learnining in 2012 synthesised an idea in porder to make great strides in computer vission\n",
    "# Now computer can identify human faces, object with high accuracy\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The hello world of mnist dataset\n",
    "The mnist data set contain a total of 70000 hand written digits along with trainig labels.\n",
    "Typically 60,000 re used for taraining the dataset\n",
    "and the remaining are used for testing the model accuracy\n",
    "This is known as supervised image classification task.\n",
    "A machine learning model must classisfy an imqgwe into one of 10 classes or categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Layers\n",
    "#Convolutional layer is the very first layer where we extract features from the images in our \n",
    "#datasets. Due to the fact that pixels are only related with the adjacent and close pixels, \n",
    "#convolution allows us to preserve the relationship between different parts of an image. \n",
    "#Convolution is basically filtering the image with a smaller pixel filter to decrease the size \n",
    "#of the image without loosing the relationship between pixels. When we apply convolution to 5x5 \n",
    "#image by using a 3x3 filter with 1x1 stride (1 pixel shift at each step). We will end up having a \n",
    "#3x3 output (64% decrease in complexity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pooling Layer\n",
    "#When constructing CNNs, it is common to insert pooling layers after each convolution layer\n",
    "#to reduce the spatial size of the representation to reduce the parameter counts which reduces \n",
    "#the computational complexity. In addition, pooling layers also helps with the overfitting problem.\n",
    "#Basically we select a pooling size to reduce the amount of the parameters by selecting the maximum,\n",
    "#average, or sum values inside these pixels. Max Pooling, one of the most common pooling techniques,\n",
    "#may be demonstrated as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A Set of Fully Connected Layers\n",
    "#A fully connected network is our RegularNet where each parameter is linked to one another to \n",
    "#determine the true relation and effect of each parameter on the labels. Since our time-space \n",
    "#complexity is vastly reduced thanks to convolution and pooling layers, we can construct a fully \n",
    "#connected network in the end to classify our images. A set of fully connected layers looks like \n",
    "#this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I have separated these two groups as train and test and also separated the labels and the images.\n",
    "#x_train and x_test parts contain greyscale RGB codes (from 0 to 255) while y_train and y_test parts contains labels from 0 to 9 \n",
    "#which represents which number they actually are. To visualize these numbers, we can get help from matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1de21504a88>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image_index = 59999 # You may select anything up to 60,000\n",
    "print(y_train[image_index]) # The label is 8\n",
    "plt.imshow(x_train[image_index], cmap='Greys')\n",
    "#When we run the code above, we will get the greyscale visualization of the RGB codes as shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We also need to know the shape of the dataset to channel it to the convolutional neural network. Therefore, I will use the “shape” attribute\n",
    "#of numpy array with the following code:\n",
    "x_train.shape\n",
    "#You will get (60000, 28, 28). As you might have guessed 60000 represents the number of images in the train dataset\n",
    "#and (28, 28) represents the size of the image: 28 x 28 pixel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping and Normalizing the Images::\n",
    "To be able to use the dataset in Keras API, we need 4-dims numpy arrays. However, as we see above, our array is 3-dims. In addition, we must normalize our data as it is always required in neural network models. We can achieve this by dividing the RGB codes to 255 (which is the maximum RGB code minus the minimum RGB code). This can be done with the following code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
    "x_train=x_train.reshape(x_train.shape[0],28,28,1)\n",
    "x_test=x_test.reshape(x_test.shape[0],28,28,1)\n",
    "input_shape=(28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making sure that we have the float type so that we can get the decimal point\n",
    "x_train=x_train.astype(\"float32\")\n",
    "x_test=x_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "Number of images in x_train 60000\n",
      "Number of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "## Normalizing the RGB codes by dividing it to the max RGB value\n",
    "x_train/=255\n",
    "x_test/=255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Convolutional Neural Network::\n",
    "We will build our model by using high level Keras API which uses either TensorFlow or Theano on the backend. I would like to mention that there are several high level TensorFlow APIs such as Layers, Keras, and Estimators which helps us create neural networks with high level knowledge. However, this may lead to confusion since they all varies in their implementation structure. Therefore, if you see completely different codes for the same neural network although they all use tensorflow, this is why. I will use the most straightforward API which is Keras. Therefore, I will import the Sequential Model from Keras and add Conv2D, MaxPooling, Flatten, Dropout, and Dense layers. I have already talked about Conv2D, Maxpooling, and Dense layers. In addition, Dropout layers fight with the overfitting by disregarding some of the neurons while training while Flatten layers flatten 2D arrays to 1D array before building the fully connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the required Keras modules containing model and layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a Sequential Model and adding the layers\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We may experiment with any number for the first Dense layer; however, the final Dense layer \n",
    "#must have 10 neurons since we have 10 number classes (0, 1, 2, …, 9). You may always experiment \n",
    "#with kernel size, pool size, activationfunctions, dropout rate, and number of neurons in the\n",
    "#first Dense layer to get a better result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling and Fitting the Model::\n",
    "With the above code, we created an non-optimized empty CNN. Now it is time to set an optimizer with a given loss function which uses a metric. Then, we can fit the model by using our train data. We will use the following code for these tasks:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.2129 - accuracy: 0.9346\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 132s 2ms/step - loss: 0.0857 - accuracy: 0.9727\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 132s 2ms/step - loss: 0.0624 - accuracy: 0.9809\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 127s 2ms/step - loss: 0.0433 - accuracy: 0.9862\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 120s 2ms/step - loss: 0.0354 - accuracy: 0.9884\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 123s 2ms/step - loss: 0.0294 - accuracy: 0.9905\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 125s 2ms/step - loss: 0.0262 - accuracy: 0.9916\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 124s 2ms/step - loss: 0.0216 - accuracy: 0.9928\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 127s 2ms/step - loss: 0.0202 - accuracy: 0.9931\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 146s 2ms/step - loss: 0.0177 - accuracy: 0.9942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2b30f7104c8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(x=x_train,y=y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can experiment with the optimizer, loss function, metrics, and epochs. However, I can say that adam optimizer is usually \n",
    "#out-performs the other optimizers. I am not sure if you can actually change the loss function for\n",
    "#multi-class classification. Feel free to experiment and comment below. Epoch number might seem a \n",
    "#bit small. However, you will reach to 98–99% test accuracy. Since the MNIST dataset does not \n",
    "#require heavy computing power, you may easily experiment with the epoch number as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Evaluating the Model ::\n",
    " Finally, you may evaluate the trained model with x_test and y_test using one line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 12s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05866284617047213, 0.9854999780654907]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "We achieved 98.5% accuracy with such basic model. To be frank, in many image classification cases (e.g. for autonomous cars), we cannot even tolerate 0.1% error since, as an analogy, it will cause 1 accident in 1000 cases. However, for our first model, I would say the result is still pretty good. We can also make individual predictions with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 7444  ### random.randrange(10000)\n",
    "plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
    "pred = model.predict(x_test[image_index].reshape(1, 28, 28, 1))\n",
    "print(pred.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# congrats\n",
    "::\n",
    "You have successfully built a convolutional neural network to classify hand written digits with Tensorflow’s Keras API. You have achieved an accuracy over 98% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
